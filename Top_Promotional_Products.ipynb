{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e958abad",
   "metadata": {},
   "source": [
    "1 - Inventory snapshot info (report)\n",
    "2 - New Product sales report wmargin\n",
    "3 - Gsheet with expiry date from CWH\n",
    "4 - Location based stick info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "a3442d9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "from datetime import date\n",
    "today = dt.now()\n",
    "mask = '%Y%m%d'\n",
    "dte = dt.now().strftime(mask)\n",
    "\n",
    "#Read the downloaded report\n",
    "Path_A = \"/Users/swaroopbasavarajmusti/Desktop/G10andGetirBuyuk_AllProducts_without_TRDE.xlsx\"\n",
    "\n",
    "Assortment = pd.read_excel(Path_A)\n",
    "\n",
    "#change the marketplace product id column name (not required but to avoid confusion)\n",
    "\n",
    "Assortment.rename(columns={'marketproduct_id':'Getir Product Id'}, inplace=True)\n",
    "\n",
    "#select only required columns\n",
    "\n",
    "Assortment = Assortment[['createdatl','updatedatl','Getir Product Id','product_barcode','marketproduct_name_de','segment_name',\n",
    "'brand_name','category_name_en','subcategory_name_en','supplier_names','net_net_buying_price_with_vat','g10_price','transfer_groups','isvisible',\\\n",
    "'isbundle','exp_days_lifetime','exp_days_allowed','exp_days_warning','exp_days_dead','inbox_quantitiy',\\\n",
    "'palet_inbox_quantity','storagetype','transfer_coli_count','is_picked_to_zero','market_status']]\n",
    "\n",
    "#filter unwanted segments from the dataframe\n",
    "Segment_filters = [\"Asset\", \"None\", \"Test\", \"Only Promo\"]\n",
    "Assortment = Assortment[~Assortment.segment_name.isin(Segment_filters)].reset_index(drop = True)\n",
    "\n",
    "#sort the values based on the date created\n",
    "Assortment = Assortment.sort_values(by=\"createdatl\",ascending = False).reset_index(drop = True)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "Path_G = '/Users/swaroopbasavarajmusti/Desktop/current_stock_info.xlsx'\n",
    "stock_df = pd.read_excel(Path_G)\n",
    "\n",
    "df = stock_df.copy()\n",
    "\n",
    "df.rename(columns={'product_id':'Getir Product Id'}, inplace=True)\n",
    "\n",
    "Closed_Warehouses = ['Alex','Aplerbeck','Barmbek_Gorillas','Berlin HUB','Bickendorf','Billstedt',\\\n",
    "           'Bispingen CW_NoNag','Boeblinger_Gorillas','Cologne - CHOCO','DE_Training_WH','Dortmund HUB - Choco',\\\n",
    "           'Dummy Berlin CW','Friedenau','Gbrunnen Fleet','Getir DE Defleet','Getir DE Office','Getir Germany Test',\\\n",
    "           'Haidhausen','Halensee','Harras','Jungfernheide','JungleTEST','Langwasser','Lichtenberg','Luft_Gorillas',\\\n",
    "           'MagnaPark CW_NoNag','Meringplatz','Munich HUB - Choco','Nordbahnhof','NÃ¼rnberg HUB - Choco','Ottensen',\\\n",
    "           'Pasing','Staaken','Stellingen','Tempelhof','Trudering','UNeukolln','Unterbilk','Unterrath','Velodrom',\\\n",
    "           'Wandsbek','Weissensee','Winsviertel','Wittenbergplatz','ZOBMesse','Zabo','Zeigner_Gorillas']\n",
    "\n",
    "CWH = ['Bispingen CW', 'MagnaPark CW']\n",
    "\n",
    "for C in Closed_Warehouses:\n",
    "    df = df[df.warehouse_name != C]\n",
    "\n",
    "warehouse_list = df.warehouse_name.unique().tolist()\n",
    "warehouse_list.remove('Bispingen CW')\n",
    "warehouse_list.remove('MagnaPark CW')\n",
    "\n",
    "df_1 = df.pivot_table(index=['Getir Product Id'],columns='warehouse_name',values = 'available',aggfunc='sum').\\\n",
    "                reset_index()\n",
    "\n",
    "#df_1.drop(columns = Closed_Warehouses)\n",
    "\n",
    "df_1['Total_MFC'] = int(0)\n",
    "for w in warehouse_list:\n",
    "    df_1[w]= df_1.fillna(0)[w].astype(int)\n",
    "    df_1['Total_MFC'] = df_1['Total_MFC'] + df_1[w]\n",
    "    \n",
    "\n",
    "df_1['Total_CWH'] = int(0)\n",
    "for w in CWH:\n",
    "    df_1[w]= df_1.fillna(0)[w].astype(int)\n",
    "    df_1['Total_CWH'] = df_1['Total_CWH'] + df_1[w]\n",
    "\n",
    "df_1['Total'] = int(0)\n",
    "df_1['Total'] = df_1['Total_MFC'] + df_1['Total_CWH']\n",
    "\n",
    "Merged_assortment_stock = pd.merge(Assortment, \n",
    "                      df_1, \n",
    "                      on ='Getir Product Id', \n",
    "                      how ='left')\n",
    "\n",
    "Merged_assortment_stock['Stock_Value_Total'] = Merged_assortment_stock['Total']*\\\n",
    "Merged_assortment_stock['net_net_buying_price_with_vat']\n",
    "Merged_assortment_stock['Stock_Value_MFC'] = Merged_assortment_stock['Total_MFC']*\\\n",
    "Merged_assortment_stock['net_net_buying_price_with_vat']\n",
    "Merged_assortment_stock['Stock_Value_CWH'] = Merged_assortment_stock['Total_CWH']*\\\n",
    "Merged_assortment_stock['net_net_buying_price_with_vat']\n",
    "Merged_assortment_stock['Stock_Value_Total'] = round(Merged_assortment_stock['Stock_Value_Total'].fillna(0).astype(int),2)\n",
    "Merged_assortment_stock['Stock_Value_MFC'] = Merged_assortment_stock['Stock_Value_MFC'].fillna(0).astype(int)\n",
    "Merged_assortment_stock['Stock_Value_CWH'] = Merged_assortment_stock['Stock_Value_CWH'].fillna(0).astype(int)\n",
    "Merged_assortment_stock['Profit/Product'] = Merged_assortment_stock['g10_price']-Merged_assortment_stock['net_net_buying_price_with_vat']\n",
    "Merged_assortment_stock['Profit/Product'] = round(Merged_assortment_stock['Profit/Product'],2)\n",
    "#cat_wise = Merged_assortment_stock.copy()\n",
    "\n",
    "#cat_wise = cat_wise.groupby(['category_name_en','subcategory_name_en']).sum('Stock_Value').reset_index()\n",
    "#cat_wise = cat_wise.sort_values('Stock_Value', ascending=False).reset_index(drop = True)\n",
    "\n",
    "Path_H = '/Users/swaroopbasavarajmusti/Desktop/marketProductSales.xlsx'\n",
    "Sales_df = pd.read_excel(Path_H)\n",
    "\n",
    "Sales_df.rename(columns={'product_id':'Getir Product Id'}, inplace=True)\n",
    "dict_of_Marketplaces = {k: v for k, v in Sales_df.groupby('integrations_breakdown')}\n",
    "Marketplaces = Sales_df['integrations_breakdown'].unique()\n",
    "Unique_ID_df = pd.DataFrame(Sales_df['Getir Product Id'].unique())\n",
    "Unique_ID_df.rename(columns={0:'Getir Product Id'}, inplace=True)\n",
    "\n",
    "All_means = pd.DataFrame()\n",
    "for M in Marketplaces:\n",
    "    df = dict_of_Marketplaces[M].copy()\n",
    "    df = df.pivot_table(index=['Getir Product Id'],columns='week',values = 'items_sold_count',aggfunc='sum').\\\n",
    "                reset_index()\n",
    "    temp_name = M +\"_mean\"\n",
    "    df[temp_name] = df.mean(numeric_only=True, axis=1)\n",
    "    df[temp_name] = df[temp_name].astype(int)\n",
    "    df = df[['Getir Product Id', temp_name ]]\n",
    "    Unique_ID_df = Unique_ID_df.merge(df, on ='Getir Product Id', how ='left')\n",
    "    \n",
    "Master = pd.merge(Merged_assortment_stock, \n",
    "                  Unique_ID_df, \n",
    "                  on ='Getir Product Id', \n",
    "                  how ='left')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "import gspread\n",
    "\n",
    "scope = ['https://www.googleapis.com/auth/spreadsheets','https://www.googleapis.com/auth/drive.file', \\\n",
    "        'https://www.googleapis.com/auth/drive','https://www.googleapis.com/auth/drive.readonly']\n",
    "\n",
    "creds = ServiceAccountCredentials.from_json_keyfile_name('panel-321812-ac5afc8690ea.json',scope)\n",
    "client = gspread.authorize(creds)\n",
    "\n",
    "Expiry_data  = client.open('Gsheet trial').worksheet('Stock')\n",
    "Expiry_df = pd.DataFrame(Expiry_data.get_all_records())\n",
    "\n",
    "Expiry_df['Today'] = dt.now().strftime('%Y%m%d')\n",
    "Expiry_df['Today'] = pd.to_datetime(Expiry_df['Today'], errors='coerce') \n",
    "\n",
    "Expiry_df['Expire date'] = pd.to_datetime(Expiry_df['Expire date'], errors='coerce')\n",
    "\n",
    "Expiry_df['Remaining_Days'] = Expiry_df['Expire date'] - Expiry_df['Today']\n",
    "Expiry_df['Remaining_Days'] = pd.to_timedelta(Expiry_df.Remaining_Days, errors='coerce').dt.days\n",
    "\n",
    "Expiry_df = Expiry_df[['Item code','Expire date','Today','Remaining_Days']]\\\n",
    ".sort_values(by = 'Remaining_Days', ascending=[True]).reset_index(drop = True)\n",
    "Expiry_df.rename(columns={'Item code':'Getir Product Id'}, inplace=True)\n",
    "\n",
    "Master_V2 = pd.merge(Master, \n",
    "                  Expiry_df, \n",
    "                  on ='Getir Product Id', \n",
    "                  how ='left')\n",
    "\n",
    "Master_V2 = Master_V2.drop_duplicates(subset=['Getir Product Id', 'Remaining_Days'])\n",
    "\n",
    "Analysis = Master_V2.copy()\n",
    "\n",
    "# Expiry date nearing data\n",
    "\n",
    "Path_I = '/Users/swaroopbasavarajmusti/Desktop/Location_Based_Stocks.xlsx'\n",
    "L2_stocks = pd.read_excel(Path_I)\n",
    "\n",
    "for C in Closed_Warehouses:\n",
    "    df = L2_stocks[L2_stocks['Warehouse Name'] != C]\n",
    "\n",
    "df_3 = df.copy()\n",
    "df_3['expiry_group'] = df_3['Expiry Date'].dt.strftime('%Y')+\"_\"+df_3['Expiry Date'].dt.strftime('%W')\n",
    "df_3['Dead_group'] = df_3['Dead Date'].dt.strftime('%Y')+\"_\"+df_3['Dead Date'].dt.strftime('%W')\n",
    "\n",
    "# 1st method\n",
    "df_4 = df_3.pivot_table(index=['Product Id'],columns=['expiry_group','Dead_group','Warehouse Name'],values = 'Quantity',aggfunc='sum', fill_value=0).\\\n",
    "                reset_index()\n",
    "\n",
    "df_6 = df_4.iloc[:,0:401]\n",
    "\n",
    "df_6.reset_index(inplace=True)\n",
    "df_6.columns = [' '.join(col).strip() for col in df_6.columns.values]\n",
    "\n",
    "# 2nd method\n",
    "df_5 = df_3.groupby(['expiry_group','Dead_group','Expiry Date','Dead Date','Warehouse Name','Product Id']).agg({\"Quantity\": \"sum\"})\\\n",
    ".reset_index().rename(columns={\"Quantity\": \"Remaining_Quantity\"})\n",
    "\n",
    "df_5.rename(columns={'Product Id':'Getir Product Id'}, inplace=True)\n",
    "\n",
    "\n",
    "expiring_products_data = pd.merge(df_5, \n",
    "                      Master, \n",
    "                      on ='Getir Product Id', \n",
    "                      how ='left')\n",
    "\n",
    "df_7 = expiring_products_data.copy()\n",
    "df_7['Remaining_days_expiry'] = df_7['Expiry Date'] - today\n",
    "df_7['Remaining_days_expiry'] = pd.to_timedelta(df_7.Remaining_days_expiry, errors='coerce').dt.days\n",
    "df_7['Remaining_days_Dead'] = df_7['Dead Date'] - today\n",
    "df_7['Remaining_days_Dead'] = pd.to_timedelta(df_7.Remaining_days_Dead, errors='coerce').dt.days\n",
    "expiring_products_30_days = df_7.loc[df_7['Remaining_days_Dead'] < 31]\n",
    "expiring_products_30_days = expiring_products_30_days[['expiry_group','Expiry Date','Dead_group','Dead Date','Warehouse Name','Getir Product Id',\\\n",
    "                                                      'Remaining_Quantity','createdatl','product_barcode','marketproduct_name_de',\\\n",
    "                                                      'segment_name','category_name_en','subcategory_name_en','supplier_names',\\\n",
    "                                                      'net_net_buying_price_with_vat','storagetype','Profit/Product','GORILLAS_mean','JET_mean',\\\n",
    "                                                      'GETIR_mean','Remaining_days_Dead','Remaining_days_expiry']]\n",
    "\n",
    "#Print all data into excel for send out\n",
    "\n",
    "with pd.ExcelWriter(\"/Users/swaroopbasavarajmusti/Desktop/Promotional_Products_{}.xlsx\".format(dte)) as writer:\n",
    "    expiring_products_30_days.to_excel(writer, sheet_name = \"Products_Expiring_30_days\")\n",
    "    for M in Marketplaces:\n",
    "        Analysis['Cover_days_'+M] = (Analysis['Total']/Analysis[M+'_mean'])*7\n",
    "        Analysis['Cover_days_'+M] = Analysis['Cover_days_'+M].fillna(0).astype(int)\n",
    "        Analysis['STR_'+M] = round((Analysis[M+'_mean']/Analysis['Total'])*100, 2)\n",
    "        Analysis['Risk_Rank_'+M] = round((Analysis['Cover_days_'+M] - Analysis['Remaining_Days']), 0).rank(ascending=False)\n",
    "        Analysis['Risk_Rank_'+M] = Analysis['Risk_Rank_'+M].fillna(0).astype(int)\n",
    "        \n",
    "        temp_df = Analysis.copy()\n",
    "        temp_df =  temp_df[(temp_df['Cover_days_'+M]>60)]\n",
    "        temp_df = temp_df[['createdatl','Getir Product Id','product_barcode','marketproduct_name_de',\\\n",
    "                          'category_name_en','subcategory_name_en','segment_name','Total_CWH','Total_MFC',\\\n",
    "                           'Total','Stock_Value_Total','Stock_Value_MFC','Stock_Value_CWH','Profit/Product',\\\n",
    "                          M+'_mean','STR_'+M,'Cover_days_'+M,'Expire date','Remaining_Days','Risk_Rank_'+M]].sort_values(by=\"Cover_days_\"+M,ascending = False).reset_index(drop = True)\n",
    "        temp_df = temp_df.sort_values(by='Risk_Rank_'+M,ascending = True).reset_index(drop = True)\n",
    "        temp_df.to_excel(writer, sheet_name = M)\n",
    "        col = \"Risk_Rank_\"+M\n",
    "        temp_df_2 = temp_df[(temp_df[col] > 0)& (temp_df[col] < 31)].reset_index(drop = True)\n",
    "        temp_df_2.to_excel(writer, sheet_name = \"top_30_\"+M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "a7862252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_5.to_excel(\"/Users/swaroopbasavarajmusti/Desktop/df_5.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
