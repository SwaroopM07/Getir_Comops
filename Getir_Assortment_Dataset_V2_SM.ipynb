{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e958abad",
   "metadata": {},
   "source": [
    "#Hard coded values\n",
    "Column names\n",
    "'createdatl,'updatedatl','marketproduct_id','Eddress ID','product_barcode','marketproduct_name_de','segment_name',\n",
    "'brand_name','category_name_en','subcategory_name_en','supplier_names','list_price,'g10_price','transfer_groups','isvisible'\n",
    "\n",
    "Segment filter\n",
    "\"Asset\", \"Delist\", \"None\", \"Test\", \"Only Promo\"\n",
    "\n",
    "category managers\n",
    "\"Marius\",\"Fabian\",\"Gina\",\"Hamid\",\"Amadeus\",\"Rozan\",\"Francisco\",\"Eike\",\"Evrim\",\"Leonard\",\"Andrea\"\n",
    "\n",
    "Cities\n",
    "\"Berlin\",\"Berlin Mini\", \"Dresden\",\"Leipzig\",\"Hamburg\",\"Bremen\",\"Hannover\",\"Düsseldorf\",\"Dortmund\",\"Köln\",\"Bonn\",\"Essen\",\"München\", \"Nürnberg/Fürth\",\"Frankfurt\",\"Offenbach\",\"Stuttgart\",\"Heidelberg\",\"Mannheim\",\"Karlsruhe\",\"Darmstadt\",\"Augsburg\"\n",
    "\n",
    "segments\tsegment_name\n",
    "1\tTest\n",
    "10\tSeasonal\n",
    "11\tSupply Shortage\n",
    "12\tStand By\n",
    "2\tLaunch\n",
    "3\tRegular\n",
    "4\tRegional\n",
    "5\tOnly Promo\n",
    "6\tDelist On Depletion\n",
    "7\tDelist\n",
    "8\tAsset\n",
    "\n",
    "\n",
    "final output columns format\n",
    "\n",
    "\n",
    "#Using Instructions\n",
    "1 - save panel report on desktop and rename until date. (ex - G10andGetirBuyuk_AllProducts_without_TRDE_20230605.xlsx)\n",
    "2 - save eddress export all on desktop and rename as Inventory.xls\n",
    "3 - run the code - you will have a sheet on your desktop \"New_assortment\"\n",
    "4 - copy the data from \"New_assortment\" and paste it in Assortment list sheet - \"Weekly updated Assortment List\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3442d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "from datetime import date\n",
    "today = dt.now()\n",
    "\n",
    "#Read the downloaded report\n",
    "Path_A = \"/Users/swaroopbasavarajmusti/Desktop/G10andGetirBuyuk_AllProducts_without_TRDE.xlsx\"\n",
    "\n",
    "Assortment = pd.read_excel(Path_A)\n",
    "\n",
    "#change the marketplace product id column name (not required but to avoid confusion)\n",
    "\n",
    "Assortment.rename(columns={'marketproduct_id':'Getir Product Id'}, inplace=True)\n",
    "\n",
    "#select only required columns\n",
    "\n",
    "Assortment = Assortment[['createdatl','updatedatl','Getir Product Id','product_barcode','marketproduct_name_de','segment_name',\n",
    "'brand_name','category_name_en','subcategory_name_en','supplier_names','net_net_buying_price_with_vat','g10_price','transfer_groups','isvisible',\\\n",
    "'isbundle','exp_days_lifetime','exp_days_allowed','exp_days_warning','exp_days_dead','inbox_quantitiy',\\\n",
    "'palet_inbox_quantity','storagetype','transfer_coli_count','is_picked_to_zero','market_status']]\n",
    "\n",
    "#filter unwanted segments from the dataframe\n",
    "Segment_filters = [\"Asset\", \"None\", \"Test\", \"Only Promo\"]\n",
    "Assortment = Assortment[~Assortment.segment_name.isin(Segment_filters)].reset_index(drop = True)\n",
    "\n",
    "#sort the values based on the date created\n",
    "Assortment = Assortment.sort_values(by=\"createdatl\",ascending = False).reset_index(drop = True)\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#creating dictionary to match the product ids\n",
    "\n",
    "Path_B = \"/Users/swaroopbasavarajmusti/Desktop/Inventory.xls\"\n",
    "Dictionary = pd.read_excel(Path_B)\n",
    "\n",
    "Dictionary = Dictionary[Dictionary['Getir Product Id'].notna()].reset_index(drop = True)\n",
    "Dictionary = Dictionary[['Getir Product Id','Product Id','Product SKU','Enabled / Disabled']]\n",
    "\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#left joining Panel assortment with eddress ID dictionary\n",
    "\n",
    "Assortment_Inventory = pd.merge(Assortment, \n",
    "                      Dictionary, \n",
    "                      on ='Getir Product Id', \n",
    "                      how ='left')\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "# read purchase order report \n",
    "\n",
    "Path_C = \"/Users/swaroopbasavarajmusti/Desktop/G10_and_GB_purchaseorderInfo.xlsx\"\n",
    "PO = pd.read_excel(Path_C)\n",
    "\n",
    "#rename primary keys and reduce to only required columns\n",
    "PO.rename(columns={'Item':'Getir Product Id'}, inplace=True)\n",
    "PO.rename(columns={'Job Status Name':'Job_status'}, inplace=True)\n",
    "\n",
    "#filter unwanted columns from the dataframe and create only required dataframe\n",
    "PO = PO[['Getir Product Id','Purchaseorder Createdat L','Job_status']]\n",
    "\n",
    "#filter unwanted job status from the dataframe and create only required dataframe\n",
    "Job_Status_Name_filters = [\"CANCELLED\"]\n",
    "PO = PO[~PO.Job_status.isin(Job_Status_Name_filters)].reset_index(drop = True)\n",
    "\n",
    "#look for unique values of products ordered and create ordered status\n",
    "Ordered_products = pd.DataFrame(data=PO['Getir Product Id'].unique(), columns=[\"Getir Product Id\"])\n",
    "Ordered_products['Order_Status'] = 'TRUE'\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#join the two table with primary\n",
    "Assortment_Joined = pd.merge(Assortment_Inventory, \n",
    "                      Ordered_products, \n",
    "                      on ='Getir Product Id', \n",
    "                      how ='left')\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#filtering only required columns\n",
    "Assortment_Joined = Assortment_Joined[['createdatl','updatedatl','Getir Product Id','Product Id','Product SKU','product_barcode','marketproduct_name_de','segment_name',\n",
    "'brand_name','category_name_en','subcategory_name_en','supplier_names','net_net_buying_price_with_vat','g10_price','isvisible','transfer_groups','Enabled / Disabled','Order_Status',\\\n",
    "'isbundle','exp_days_lifetime','exp_days_allowed','exp_days_warning','exp_days_dead','inbox_quantitiy',\\\n",
    "'palet_inbox_quantity','storagetype','transfer_coli_count','is_picked_to_zero','market_status']]\n",
    "\n",
    "#convert datetime format to just date\n",
    "Assortment_Joined['createdatl'] = Assortment_Joined['createdatl'].dt.date\n",
    "Assortment_Joined['updatedatl'] = Assortment_Joined['updatedatl'].dt.date\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#create categories and categories manager dictionary\n",
    "Category_dictionary = {\\\n",
    "\"Rozan\":['Coffee & Tea'],\n",
    "\"Marius\":['Baby','Beer','Home Care','Personal Care','Pets','Spirits & Co.','Wine & Co.'],\n",
    "\"Leonard\":['Fruit & Veg'],\n",
    "\"Hamid\":['Cheese & Co.','Milk & Eggs','Yoghurt & Co.','Cold Cuts','Meat & Fish'],\n",
    "\"Francisco\":['Fresh & Ready'],\n",
    "\"Fabian\":['Bakery'],\n",
    "\"Evrim\":['Frozen Food','Ice Cream'],\n",
    "\"Eike\":['Drinks','Breakfast','Pantry','Pasta & Rice','Canned','Crisps & Snacks'],\n",
    "\"Amadeus\":['Christmas','Easter','Sweet Snacks'],\n",
    "\"Other\":['0','DUMMY TEST KATEGORI GE',\"Mother's Day\",'Top Deals','Earthquake Aid','Dairy','Cheese & Deli','Vegan & Veggie','Confectionery','Vegan']}\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#match the categories and get the name of category manager\n",
    "for ind, row in Assortment_Joined.iterrows():\n",
    "    if Assortment_Joined.loc[ind, 'category_name_en'] == \"\":\n",
    "        Assortment_Joined.loc[ind, 'Buyer'] = \"Not Assigned\"\n",
    "    else:\n",
    "        Category = Assortment_Joined.loc[ind, 'category_name_en']\n",
    "        Assortment_Joined.loc[ind, 'Buyer'] = [k for k, v in Category_dictionary.items() if Category in v]\n",
    "\n",
    "\n",
    "# #get only the name without brackets\n",
    "#Assortment_Joined['Buyer'] = ''\n",
    "Assortment_Joined['Buyer'] = Assortment_Joined['Buyer'].astype(str)\n",
    "Assortment_Joined['Buyer'] = Assortment_Joined['Buyer'].str[2:-2]\n",
    "\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#change the eddress enabled/disabled status to true and false\n",
    "for ind,row in Assortment_Joined.iterrows():\n",
    "    if Assortment_Joined.loc[ind, 'Enabled / Disabled'] == 'Enabled':\n",
    "        Assortment_Joined.loc[ind, 'Live Gorillas app'] = \"TRUE\"\n",
    "    else:\n",
    "        Assortment_Joined.loc[ind, 'Live Gorillas app'] = \"FALSE\"\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "#------------------------------\n",
    "\n",
    "#Generate the y/n combination for transfer group(mfc) checks\n",
    "Assortment_Joined['transfer_groups'] = Assortment_Joined['transfer_groups'].astype(str)\n",
    "\n",
    "#create a list of cities \n",
    "cities = [\"Berlin\",\"Berlin mini\", \"Dresden\",\"Leipzig\",\"Hamburg\",\"Bremen\",\\\n",
    "          \"Hannover\",\"Düsseldorf\",\"Dortmund\",\"Köln\",\"Bonn\",\"Essen\",\"München\",\\\n",
    "          \"NürnbergFürth\",\"Frankfurt\",\"Offenbach\",\"Stuttgart\",\"Heidelberg\",\\\n",
    "          \"Mannheim\",\"Karlsruhe\",\"Darmstadt\",\"Augsburg\"]\n",
    "\n",
    "Assortment_Joined['Cities'] = ''\n",
    "#iterate over transfer groups to check for cities\n",
    "for c in cities:\n",
    "    for ind, row in Assortment_Joined.iterrows():\n",
    "        x = \"merged \"+c\n",
    "        if c in Assortment_Joined.loc[ind, 'transfer_groups']:\n",
    "            Assortment_Joined.loc[ind, c] = \"Y\"\n",
    "            a = Assortment_Joined.loc[ind, 'Cities']\n",
    "            b = c\n",
    "            new_Cit = a+\", \"+b\n",
    "            Assortment_Joined.loc[ind, 'Cities'] = new_Cit\n",
    "        else:\n",
    "            Assortment_Joined.loc[ind, c] = \"N\"\n",
    "            \n",
    "Assortment_Joined['Cities'] = Assortment_Joined['Cities'].str[2:]\n",
    "#------------------------------\n",
    "\n",
    "#renaming and del column\n",
    "Assortment_Joined.rename(columns={'createdatl':'Product Card Creation Date'}, inplace=True)\n",
    "Assortment_Joined.rename(columns={'updatedatl':'Update date'}, inplace=True)\n",
    "Assortment_Joined.rename(columns={'net_net_buying_price_with_vat':'Buying Price (w VAT)'}, inplace=True)\n",
    "Assortment_Joined.rename(columns={'g10_price':'Selling Price (w VAT)'}, inplace=True)\n",
    "Assortment_Joined.rename(columns={'isvisible':'Live Getir app'}, inplace=True)\n",
    "Assortment_Joined.rename(columns={'Product Id':'Eddress Product Id'}, inplace=True)\n",
    "Assortment_Joined.rename(columns={'product_barcode':'GTIN_Panel'}, inplace=True)\n",
    "Assortment_Joined.rename(columns={'Product SKU':'GTIN_Eddress'}, inplace=True)\n",
    "Assortment_Joined.rename(columns={'segment_name':'Segment_Panel'}, inplace=True)\n",
    "\n",
    "#------------------------------\n",
    "#additional formatting\n",
    "Assortment_Joined['Update date'] = ''\n",
    "del Assortment_Joined['transfer_groups']\n",
    "Assortment_Joined['Order_Status'] = Assortment_Joined['Order_Status'].fillna('FALSE')\n",
    "del Assortment_Joined['Enabled / Disabled']\n",
    "        \n",
    "#------------------------------\n",
    "\n",
    "#sorting and reset index\n",
    "Assortment_Joined.sort_values(by='Product Card Creation Date', ascending = False ,inplace = True)\n",
    "Assortment_Joined = Assortment_Joined.reset_index(drop=True)\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "#adding mdm data to dataset to get the product status on mdm\n",
    "\n",
    "Path_D = \"/Users/swaroopbasavarajmusti/Desktop/mdm_data.xlsm\"\n",
    "mdm_data_all = pd.read_excel(Path_D,'Entities')\n",
    "mdm_data_all = mdm_data_all.rename(columns=mdm_data_all.iloc[0])\n",
    "mdm_data_all = mdm_data_all.iloc[1:].reset_index(drop = True)\n",
    "mdm_data = mdm_data_all.copy()\n",
    "mdm_data = mdm_data[['Eddress Product ID','Web Pages.File Name','Product Status']]\n",
    "mdm_data = mdm_data[mdm_data['Eddress Product ID'].notna()].reset_index(drop =True)\n",
    "mdm_data.rename(columns={'Eddress Product ID':'Eddress Product Id'}, inplace=True)\n",
    "mdm_data.rename(columns={'Product Status':'Segment_MDM'}, inplace=True)\n",
    "mdm_data = mdm_data.drop_duplicates(subset=['Eddress Product Id'], keep='first')\n",
    "check1 = mdm_data.copy()\n",
    "\n",
    "Merged_assortment = pd.merge(Assortment_Joined, \n",
    "                      mdm_data, \n",
    "                      on ='Eddress Product Id', \n",
    "                      how ='left')\n",
    "\n",
    "#-------------------------------\n",
    "#checking if the product is created on eddress by creating a column\n",
    "\n",
    "for ind,row in Merged_assortment.iterrows():\n",
    "    if pd.isnull(Merged_assortment.loc[ind, 'Eddress Product Id']) == True:\n",
    "        Merged_assortment.loc[ind, 'Created on Eddress'] = \"FALSE\"\n",
    "    else:\n",
    "        Merged_assortment.loc[ind, 'Created on Eddress'] = \"TRUE\"\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "#create segment dictionary and segment attributes to sync statuses\n",
    "Segment_Dictionary = {\\\n",
    "\n",
    "\"PUBLISHED\":['Regular','Regional'],\n",
    "\"UNPUBLISHED - New Ingoing\":['Launch'],\n",
    "\"PUBLISHED - Deplete\":['Seasonal','Only Promo','Delist On Depletion','Consumable'],\n",
    "\"UNAVAILABLE - OOS Supplier\":['Stand By','Supply Shortage'],\n",
    "\"UNPUBLISHED - Delisted\":['Delist','None','Asset','Test']\n",
    "\n",
    "}\n",
    "\n",
    "#create new segment statuts based on dictionary\n",
    "for ind, row in Merged_assortment.iterrows():\n",
    "    if pd.isnull(Merged_assortment.loc[ind, 'Segment_Panel']) == True:\n",
    "        Merged_assortment.loc[ind, 'Segment_New'] = \"\"\n",
    "    else:\n",
    "        segment = str(Merged_assortment.loc[ind, 'Segment_Panel'])\n",
    "        Merged_assortment.loc[ind, 'Segment_New'] = [k for k, v in Segment_Dictionary.items() if segment in v]\n",
    "\n",
    "#get only the Segments without brackets\n",
    "Merged_assortment['Segment_New'] = Merged_assortment['Segment_New'].astype(str)\n",
    "Merged_assortment['Segment_New'] = Merged_assortment['Segment_New'].str[2:-2]\n",
    "\n",
    "#create a filter column to filter products that have to be updated\n",
    "for ind, row in Merged_assortment.iterrows():\n",
    "    if pd.isnull(Merged_assortment.loc[ind, 'Segment_MDM']) == True:\n",
    "        Merged_assortment.loc[ind, 'Segment_update'] = \"\"\n",
    "    elif Merged_assortment.loc[ind, 'Segment_New'] == Merged_assortment.loc[ind, 'Segment_MDM']:\n",
    "        Merged_assortment.loc[ind, 'Segment_update'] = False\n",
    "    else:\n",
    "        Merged_assortment.loc[ind, 'Segment_update'] = True\n",
    "\n",
    "#-------------------------------\n",
    "#vhange price volumns to euro currency format\n",
    "\n",
    "Merged_assortment[\"Buying Price (w VAT)\"] = Merged_assortment[\"Buying Price (w VAT)\"].map(\"€ {:_.2f}\".format).str.translate(str.maketrans(\"_.\", \".,\"))\n",
    "Merged_assortment[\"Selling Price (w VAT)\"] = Merged_assortment[\"Selling Price (w VAT)\"].map(\"€ {:_.2f}\".format).str.translate(str.maketrans(\"_.\", \".,\"))\n",
    "\n",
    "\n",
    "#-------------------------------\n",
    "#bring relistings and delistings dataframe and add it to main df\n",
    "#path and load from desktop\n",
    "Path_f = '/Users/swaroopbasavarajmusti/Desktop/productCardChange.xlsx'\n",
    "metadata = pd.read_excel(Path_f)\n",
    "today = date.today()\n",
    "\n",
    "#filter for delist on depletion product with ids\n",
    "Dod = metadata.copy()\n",
    "Dod = Dod.loc[Dod['updated_field'] == 'segments']\n",
    "Dod = Dod.sort_values(by=\"updated_at\",ascending = False)\n",
    "Dod = Dod.drop_duplicates(subset=['product_id'], keep='first')\n",
    "Dod = Dod.loc[Dod['new_value'] == 6]\n",
    "Dod['updated_at'] = Dod['updated_at'].dt.date\n",
    "Dod['Date_filter'] = today - Dod['updated_at']\n",
    "Dod['Date_filter'] = pd.to_timedelta(Dod.Date_filter, errors='coerce').dt.days\n",
    "#Dod = Dod.loc[Dod['Date_filter'] < 14].reset_index(drop = True)\n",
    "#create column as Action and fill in \"Delist on depletion\"\n",
    "Dod['Action'] = 'Delist On Depletion'\n",
    "Dod = Dod[['product_id','updated_at','Action']]\n",
    "\n",
    "#filter for Relist product with ids\n",
    "Rel = metadata.copy()\n",
    "Rel = Rel.loc[Rel['updated_field'] == 'segments']\n",
    "Rel = Rel.sort_values(by=\"updated_at\",ascending = False)\n",
    "Rel = Rel.drop_duplicates(subset=['product_id'], keep='first')\n",
    "Rel = Rel.loc[Rel['old_value'] == 7]\n",
    "nv_filter = [6]\n",
    "Rel = Rel[~Rel.new_value.isin(nv_filter)].reset_index(drop = True)\n",
    "Rel['updated_at'] = Rel['updated_at'].dt.date\n",
    "Rel['Date_filter'] = today - Rel['updated_at']\n",
    "Rel['Date_filter'] = pd.to_timedelta(Rel.Date_filter, errors='coerce').dt.days\n",
    "#Rel = Rel.loc[Rel['Date_filter'] < 14].reset_index(drop = True)\n",
    "#create column as Action and fill in \"Relisting\"\n",
    "Rel['Action'] = 'Relisting'\n",
    "Rel = Rel[['product_id','updated_at','Action']]\n",
    "\n",
    "#2nd filter for Relist product with ids\n",
    "Rel2 = metadata.copy()\n",
    "Rel2 = Rel2.loc[Rel2['updated_field'] == 'segments']\n",
    "Rel2 = Rel2.sort_values(by=\"updated_at\",ascending = False)\n",
    "Rel2 = Rel2.drop_duplicates(subset=['product_id'], keep='first')\n",
    "Rel2 = Rel2.loc[Rel2['old_value'] == 6]\n",
    "#Rel2 = Rel2.loc[Rel2['new_value'] == 2]\n",
    "nv_filter = [2]\n",
    "Rel2 = Rel2[Rel2.new_value.isin(nv_filter)].reset_index(drop = True)\n",
    "Rel2['updated_at'] = Rel2['updated_at'].dt.date\n",
    "Rel2['Date_filter'] = today - Rel2['updated_at']\n",
    "Rel2['Date_filter'] = pd.to_timedelta(Rel2.Date_filter, errors='coerce').dt.days\n",
    "#Rel = Rel.loc[Rel['Date_filter'] < 14].reset_index(drop = True)\n",
    "#create column as Action and fill in \"Relisting\"\n",
    "Rel2['Action'] = 'Relisting'\n",
    "Rel2 = Rel2[['product_id','updated_at','Action']]\n",
    "\n",
    "#filter for Delistings product with ids\n",
    "Del = metadata.copy()\n",
    "Del = Del.loc[Del['updated_field'] == 'segments']\n",
    "Del = Del.sort_values(by=\"updated_at\",ascending = False)\n",
    "Del = Del.drop_duplicates(subset=['product_id'], keep='first')\n",
    "#Del = Del.loc[Del['old_value'] == 6]\n",
    "Del = Del.loc[Del['new_value'] == 7]\n",
    "#nv_filter = [2]\n",
    "#Del = Del[Del.new_value.isin(nv_filter)].reset_index(drop = True)\n",
    "Del['updated_at'] = Del['updated_at'].dt.date\n",
    "Del['Date_filter'] = today - Del['updated_at']\n",
    "Del['Date_filter'] = pd.to_timedelta(Del.Date_filter, errors='coerce').dt.days\n",
    "#Rel = Rel.loc[Rel['Date_filter'] < 14].reset_index(drop = True)\n",
    "#create column as Action and fill in \"Relisting\"\n",
    "Del['Action'] = 'Delisted'\n",
    "Del = Del[['product_id','updated_at','Action']]\n",
    "\n",
    "#Concat delist on depletions df and Relisting in one table and format\n",
    "Updates = pd.concat([Dod,Rel, Rel2,Del],ignore_index=True).reset_index(drop=True)\n",
    "Updates = Updates.sort_values(by=\"updated_at\",ascending = False)\n",
    "Updates = Updates.drop_duplicates(subset=['product_id'], keep='first')\n",
    "Updates.rename(columns={'product_id':'Getir Product Id'}, inplace=True)\n",
    "\n",
    "#merge with Main df to add the Action and update date to main df\n",
    "weekly_assortment = pd.merge(Merged_assortment, \n",
    "                      Updates, \n",
    "                      on ='Getir Product Id', \n",
    "                      how ='left')\n",
    "\n",
    "weekly_assortment['Update date'] = weekly_assortment['updated_at']\n",
    "\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "#organising the columns based on requirements\n",
    "weekly_assortment = weekly_assortment[[\\\n",
    "#Update dates\n",
    "'Action',\\\n",
    "'Product Card Creation Date',\\\n",
    "'Update date',\\\n",
    "\n",
    "#ids\n",
    "'Getir Product Id',\\\n",
    "'Eddress Product Id',\\\n",
    "\n",
    "#segments\n",
    "'Created on Eddress',\\\n",
    "'Segment_MDM',\\\n",
    "'Segment_Panel',\\\n",
    "\n",
    "#product statusus on multiple tools\n",
    "'Live Getir app',\\\n",
    "'Live Gorillas app',\\\n",
    "\n",
    "#gtins details\n",
    "'GTIN_Eddress',\\\n",
    "'GTIN_Panel',\\\n",
    "'marketproduct_name_de',\\\n",
    "'brand_name',\\\n",
    "'category_name_en',\\\n",
    "'subcategory_name_en',\\\n",
    "'supplier_names',\\\n",
    "'Buying Price (w VAT)',\\\n",
    "'Selling Price (w VAT)',\\\n",
    "'Buyer',\\\n",
    "\n",
    "\n",
    "#MFCs\n",
    "'Berlin','Berlin mini','Dresden','Leipzig','Hamburg','Bremen','Hannover','Düsseldorf','Dortmund','Köln','Bonn','Essen','München','NürnbergFürth','Frankfurt','Offenbach','Stuttgart','Heidelberg','Mannheim','Karlsruhe','Darmstadt','Augsburg',\\\n",
    "\n",
    "#Cityjoin\n",
    "'Cities',\\\n",
    "#filters\n",
    "'Order_Status',\\\n",
    "    \n",
    "#logistic details\n",
    "'isbundle','exp_days_lifetime','exp_days_allowed','exp_days_warning','exp_days_dead','inbox_quantitiy',\\\n",
    "'palet_inbox_quantity','storagetype','transfer_coli_count','is_picked_to_zero','market_status'\n",
    "]]\n",
    "\n",
    "\n",
    "\n",
    "#-------------------------------\n",
    "\n",
    "#Create a ouptut to excel\n",
    "weekly_assortment.to_excel(\"/Users/swaroopbasavarajmusti/Desktop/weekly_assortment.xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf0d3d6",
   "metadata": {},
   "source": [
    "Gorillas Only Products: Private Label Products: Indy started a list here - let’s use some kind of dictionary like that: https://docs.google.com/spreadsheets/d/1HbBSPP495FKP2syAOkbMEPOGrlFozz0LzI2T0H1mV44/edit#gid=979825498\n",
    "Getir only products: Define List (Chris)\n",
    "Columns to add (middterm):\n",
    "Local/Regional/National products: define rule depending on transfer groups"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
